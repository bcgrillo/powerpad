## Resumen

El presente trabajo se centra en el desarrollo de una aplicación de escritorio que permite la interacción con modelos de lenguaje de gran tamaño (**LLMs**) de forma local, combinando accesibilidad, personalización y eficiencia. La solución propuesta se basa en **Ollama** como motor de ejecución y busca eliminar la dependencia de servicios en la nube, garantizando así **privacidad, control sobre los datos y optimización del rendimiento** en hardware local.

El sistema se concibe como una herramienta **productiva e intuitiva**, que integra en un mismo entorno la **gestión de notas, la administración de conversaciones con IA y la personalización de asistentes**. A través de una interfaz moderna basada en **WinUI con .NET**, los usuarios podrán acceder a capacidades avanzadas de IA local, como **conversaciones, edición de texto y generación de contenido**, con la posibilidad de configurar asistentes personalizados para **resumir, traducir, corregir y mejorar textos** sin necesidad de abandonar su flujo de trabajo. Además, se implementa una **paleta de accesos directos personalizables**, que facilita la interacción con los modelos y optimiza la experiencia del usuario.

Uno de los aspectos diferenciadores del proyecto es la capacidad de **gestionar modelos de IA en local de forma sencilla**, permitiendo la **búsqueda, descarga, actualización y configuración** de modelos sin necesidad de conocimientos técnicos avanzados. Asimismo, se contempla la posibilidad de operar en un **entorno híbrido**, almacenando las conversaciones localmente, pero permitiendo la conexión con modelos alojados en servidores privados o en la nube según las preferencias del usuario.

(REVISAR)
Para maximizar la utilidad de la aplicación, se introducen técnicas avanzadas como la **vectorización de documentos para búsqueda semántica (RAG)**, el uso de **modelos multimodales** para reconocimiento de **sonido e imágenes**, y la posibilidad de **configurar asistentes cooperativos con múltiples roles**, que permitan encadenar tareas de IA de manera eficiente.

En el ámbito técnico, el proyecto incluye un **benchmarking** que evalúa el rendimiento en distintos entornos y con diversos modelos, comparándolo con soluciones existentes tanto locales como en la nube. Se ha llevado a cabo un **análisis de la competencia**, identificando los factores diferenciadores frente a herramientas similares.

Más allá del impacto técnico, se analizan los aspectos **sociales, éticos y ambientales** de la inteligencia artificial generativa, así como el papel de este proyecto en la democratización del acceso a modelos de IA de código abierto.

En conclusión, este trabajo presenta una solución innovadora que **integra modelos de IA en el flujo de trabajo del usuario de manera fluida y eficiente, sin comprometer la privacidad ni la seguridad de los datos**. Con su enfoque **modular y escalable**, la aplicación sienta las bases para futuras extensiones y mejoras, presentándose como una herramienta clave para la **productividad asistida por IA en entornos locales**.


## Abstract

(LO MISMO PERO EN INGLÉS)