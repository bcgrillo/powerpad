1. En el texto alternativo de las imágenes de las figuras 2.1, 2.2 y 2.3, todas usan la misma ruta `./Pictures/remove.png`, lo que parece un error o marcador de posición. Se debe corregir la ruta para que apunte a la imagen correcta o reemplazar la imagen si corresponde.

2. En la imagen con texto alternativo "Figura 2.1. Representación de la operación semántica: Obtener la capital de un país...", la numeración "Figura 2.1" está repetida respecto a la figura anterior (línea temporal). Se debe corregir la numeración para que sea única y secuencial (por ejemplo, "Figura 2.4" o la que corresponda).

3. En la imagen con texto alternativo "Figura 2.2. Ejemplo del modelo de atención representado como un grafo...", la numeración "Figura 2.2" está repetida respecto a la figura anterior (línea temporal). Se debe corregir la numeración para que sea única y secuencial.

4. En la imagen con texto alternativo "Figura 2.3. Interfaz web de TextSynth para generación de texto...", la numeración "Figura 2.3" está repetida respecto a la figura anterior (línea temporal). Se debe corregir la numeración para que sea única y secuencial.

5. En la sección 2.2.1, el término "propabilidad" está mal escrito; debe ser "probabilidad".

6. En la sección 2.2.1, en la frase "como si todas se sentasen en una mesa redonda y hablasen entre ellas", el verbo "sentasen" debería ser "sentaran" para concordar con el modo subjuntivo en este contexto (aunque es un error menor, afecta la corrección gramatical).

9. En la sección 2.1.1, en el ítem "- **2023: Popularización de los *small language models* (SLMs)**", la palabra "destilación" aparece en la cita [@destilación_2024] con tilde, lo cual es correcto en español, pero debe verificarse que la referencia esté bien escrita y no contenga caracteres especiales que puedan afectar la compilación.

10. En la sección 2.1.1, en el ítem "- **2024: Modelos que razonan: IA explicativa y precisa**", el modelo "o1" está en minúscula, mientras que otros modelos como GPT-3 o Claude 3 usan mayúsculas o números. Se recomienda verificar si "o1" es el nombre oficial del modelo o si debe ir en mayúscula ("O1").

13. En la sección 2.1.2, en el apartado *Fine-tuning*, la frase "facilitar información a cliente o usuarios" carece de artículo antes de "cliente"; debería ser "facilitar información a clientes o usuarios".

14. En la sección 2.2.1, en la frase "Gracias a este enfoque, se logra una comprensión del contexto mucho más profunda en comparación a arquitecturas anteriores", la preposición correcta es "en comparación con", no "en comparación a".

15. En la sección 2.2.1, en el texto alternativo de la imagen "Figura 2.1. Representación de la operación semántica...", la fuente está indicada como "Wikimedia -@fig_word_embedding_2025", pero el identificador de la referencia tiene un guion delante, lo que puede causar problemas en la compilación. Se recomienda eliminar el guion o verificar el formato correcto.

16. En la sección 2.2.1, en la frase "Con el **mecanismo de atención** es como si todas las palabras de un texto se miraran a unas las otras", falta la preposición "a" después de "miraran": debe decir "se miraran unas a las otras".

17. En la sección 2.2.1, en la frase "Cada vector ya no representa solo a un token independiente", la palabra "token" debería ir en cursiva (_token_) para mantener la consistencia con otras apariciones.

19. En la sección 2.2.1, en la frase "En los últimos años, junto con el crecimiento de los modelos, ha surgido un ecosistema de modelos ***open source*** y ***open weight***", el uso de tres asteriscos para combinar negrita y cursiva no está justificado según las reglas (solo cursiva para palabras en inglés, negrita solo en primera aparición o casos justificados). Se recomienda usar solo cursiva para "open source" y "open weight" (ya que son palabras en inglés), sin negrita.

20. En la sección 2.2.2, en la frase "Los modelos de lenguaje se entrenaron inicialmente para generar texto libre a partir de un *prompt*, pero para mantener interacciones coherentes y útiles en conversaciones la mayoría de modelos generativos actuales también son entrenados con datos estructurados en forma de **diálogos**", falta una coma después de "conversaciones" para mejorar la claridad.

22. En la sección 2.2.2, en la frase "Esto es lo que permite al modelo "saber" quién habla y qué tipo de respuesta se espera", las comillas deben ser comillas españolas (« ») o comillas dobles estándar, pero no comillas inglesas (""). Sin embargo, no es un error grave.

25. En la sección 2.2.3, en el apartado "Técnicas de optimización", en el ítem sobre destilación, la frase "con menos menos parámetros" tiene una repetición de la palabra "menos". Debe corregirse a "con menos parámetros".

26. En la sección 2.2.3, en el apartado "Formatos más comunes para modelos locales", la descripción de GGUF indica que es "*GPT Grammar Unified Format*", pero esta denominación no es correcta según la documentación oficial; GGUF significa "GGML Unified Format". Se debe corregir la definición para evitar error factual.

35. En la sección 2.3.1, en el apartado "Nuevas tendencias", la lista mezcla viñetas con asteriscos y guiones. Se recomienda uniformizar el formato de listas para evitar errores de Markdown.

42. En la sección 2.3.2, en el apartado "Herramientas de productividad de escritorio", la palabra "subscripción" está mal escrita; debe ser "suscripción".

43. En la sección 3.3.4 (probablemente debería ser 2.3.4), el título "Comparativa de enfoques, ventajas y limitaciones" tiene un error en la numeración del capítulo; debe corregirse a "2.3.4" para mantener la coherencia.

44. En la sección 3.3.4, en la frase "dependen de la conectividad a la nube y pueden presentar limitaciones en cuanto a la personalización y privacidad, sobre todo en las modalidades sin pago de subscripción", la palabra "subscripción" debe corregirse a "suscripción".

50. En las listas, el uso de guiones y asteriscos es mayormente consistente, salvo en el apartado "Nuevas tendencias" donde se mezclan ambos; se recomienda uniformizar.