@software{llama.cpp_2025,
	title = {ggml-org/llama.cpp},
	copyright = {MIT},
	url = {https://github.com/ggml-org/llama.cpp},
	abstract = {LLM inference in C/C++},
	urldate = {2025-06-09},
	publisher = {ggml},
	month = jun,
	year = {2025},
	note = {original-date: 2023-03-10T18:58:00Z},
	keywords = {llama, ggml},
}

@misc{connatser,
	title = {How this open source LLM chatbot runner hit the gas on x86, Arm CPUs},
	url = {https://www.theregister.com/2024/04/03/llamafile_performance_gains/},
	abstract = {Way to whip that LLaMA's ass},
	language = {en},
	urldate = {2025-06-12},
	author = {Connatser, Matthew},
	month = apr,
	year = {2024},
}

@misc{ollama,
	title = {Ollama},
	url = {https://ollama.com},
	abstract = {Get up and running with large language models.},
	urldate = {2025-06-09},
}


@misc{ollama_integrations,
	title = {Ollama, {Community} {Integrations}, {Web} \& {Desktop}},
	copyright = {MIT},
	url = {https://github.com/ollama/ollama/blob/main/README.md#web--desktop},
	abstract = {Get up and running with Llama 3.3, DeepSeek-R1, Phi-4, Gemma 3, Mistral Small 3.1 and other large language models.},
	urldate = {2025-06-12},
	publisher = {Ollama},
	month = jun,
	year = {2025},
	note = {original-date: 2023-06-26T19:39:32Z},
	keywords = {go, golang, llama, gemma, mistral, llm, llms, llava, llama2, ollama, qwen, deepseek, llama3, phi3, gemma2, phi4, gemma3},
}

@misc{john_MVVM_2005,
	title = {Introduction to {Model}/{View}/{ViewModel} pattern for building {WPF} apps},
	url = {https://learn.microsoft.com/en-us/archive/blogs/johngossman/introduction-to-modelviewviewmodel-pattern-for-building-wpf-apps},
	language = {en-us},
	urldate = {2025-06-12},
	author = {Gossman, John},
	month = oct,
	year = {2005},
}

@misc{windows_sdk,
	title = {Build desktop {Windows} apps with the {Windows} {App} {SDK} - {Windows} apps},
	url = {https://learn.microsoft.com/en-us/windows/apps/windows-app-sdk/},
	abstract = {Learn about the Windows App SDK, benefits it provides to developers, what is ready for developers now, and how to give feedback.},
	language = {en-us},
	urldate = {2025-06-12},
}

@misc{net_8,
	title = {What's new in .{NET} 8},
	url = {https://learn.microsoft.com/en-us/dotnet/core/whats-new/dotnet-8/overview},
	abstract = {Learn about the new .NET features introduced in .NET 8.},
	language = {en-us},
	urldate = {2025-06-09},
}

@misc{comprehensive_2023,
	title = {A {Comprehensive} {Survey} of {AI}-{Generated} {Content} ({AIGC}): {A} {History} of {Generative} {AI} from {GAN} to {ChatGPT}},
	shorttitle = {A {Comprehensive} {Survey} of {AI}-{Generated} {Content} ({AIGC})},
	url = {http://arxiv.org/abs/2303.04226},
	doi = {10.48550/arXiv.2303.04226},
	abstract = {Recently, ChatGPT, along with DALL-E-2 and Codex,has been gaining significant attention from society. As a result, many individuals have become interested in related resources and are seeking to uncover the background and secrets behind its impressive performance. In fact, ChatGPT and other Generative AI (GAI) techniques belong to the category of Artificial Intelligence Generated Content (AIGC), which involves the creation of digital content, such as images, music, and natural language, through AI models. The goal of AIGC is to make the content creation process more efficient and accessible, allowing for the production of high-quality content at a faster pace. AIGC is achieved by extracting and understanding intent information from instructions provided by human, and generating the content according to its knowledge and the intent information. In recent years, large-scale models have become increasingly important in AIGC as they provide better intent extraction and thus, improved generation results. With the growth of data and the size of the models, the distribution that the model can learn becomes more comprehensive and closer to reality, leading to more realistic and high-quality content generation. This survey provides a comprehensive review on the history of generative models, and basic components, recent advances in AIGC from unimodal interaction and multimodal interaction. From the perspective of unimodality, we introduce the generation tasks and relative models of text and image. From the perspective of multimodality, we introduce the cross-application between the modalities mentioned above. Finally, we discuss the existing open problems and future challenges in AIGC.},
	urldate = {2025-06-09},
	publisher = {arXiv},
	author = {Cao, Yihan and Li, Siyu and Liu, Yixin and Yan, Zhiling and Dai, Yutong and Yu, Philip S. and Sun, Lichao},
	month = mar,
	year = {2023},
	note = {arXiv:2303.04226},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}


@book{murphy_introduction_2000,
	address = {Cambridge, Mass.},
	series = {Intelligent robotics and autonomous agents},
	title = {Introduction to {AI} robotics},
	isbn = {9780262133838},
	url = {https://archive.org/details/introductiontoai0000murp},
	abstract = {Machine generated contents note: I Robotic Paradigms 1 -- 1 From Teleoperation To Autonomy 13 -- 2 The Hierarchical Paradigm 41 -- 3 Biological Foundations of the Reactive Paradigm 67 -- 4 The Reactive Paradigm 105 -- 5 Designing a Reactive Implementation 155 -- 6 Common Sensing Techniquesfor Reactive Robots 195 -- 7 The Hybrid Deliberative/Reactive Paradigm 257 -- 8 Multi-agents 293 -- II Navigation 315 -- 9 Topological Path Planning 325 -- 10 Metric Path Planning 351 -- 11 Localization and Map Making 375 -- 12 On the Horizon 435},
	language = {eng},
	publisher = {MIT Press},
	author = {Murphy, Robin R.},
	year = {2000},
}

@misc{historia_ia_2018,
	title = {Historia de la IA: Frank Rosenblatt y el Mark I Perceptrón, el primer ordenador fabricado específicamente para crear redes neuronales en 1957},
	url = {https://web.archive.org/web/20180722124753/https://data-speaks.luca-d3.com/2018/07/historia-de-la-ia-frank-rosenblatt-y-el.html},
	urldate = {2025-06-12},
	author = {Ramírez, Fran},
	month = jul,
	year = {2018},
}

@article{tealab_time_2018,
	title = {Time series forecasting using artificial neural networks methodologies: {A} systematic review},
	volume = {3},
	issn = {2314-7288},
	shorttitle = {Time series forecasting using artificial neural networks methodologies},
	url = {https://www.sciencedirect.com/science/article/pii/S2314728817300715},
	doi = {10.1016/j.fcij.2018.10.003},
	number = {2},
	urldate = {2025-06-12},
	journal = {Future Computing and Informatics Journal},
	author = {Tealab, Ahmed},
	month = dec,
	year = {2018},
	keywords = {Forecasting, Nonlinear time series, Neural networks, Moving averages},
	pages = {334--340},
}

@Article{Hinton2006,
	author = {Geoffrey E. Hinton and Simon Osindero and Y. Teh},
	booktitle = {Neural Computation},
	journal = {Neural Computation},
	pages = {1527-1554},
	title = {A Fast Learning Algorithm for Deep Belief Nets},
	volume = {18},
	year = {2006}
}

@misc{ibm_cnn_2021,
	title = {¿{Qué} son las redes neuronales convolucionales? {\textbar} {IBM}},
	shorttitle = {¿{Qué} son las redes neuronales convolucionales?},
	url = {https://www.ibm.com/es-es/think/topics/convolutional-neural-networks},
	language = {es-es},
	urldate = {2025-06-12},
	month = oct,
	year = {2021},
}

@misc{GAN_2014,
	title = {Generative Adversarial Nets},
	url = {https://arxiv.org/pdf/1406.2661},
	abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
	language = {en},
	urldate = {2025-06-09},
	journal = {arXiv.org},
	author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	month = jun,
	year = {2014},
}


@misc{gpt-2_2024,
	title = {{GPT}-2: 1.{5B} release},
	shorttitle = {{GPT}-2},
	url = {https://openai.com/index/gpt-2-1-5b-release/},
	abstract = {As the final model release of GPT-2’s staged release, we’re releasing the largest version (1.5B parameters) of GPT-2 along with code and model weights to facilitate detection of outputs of GPT-2 models. While there have been larger language models released since August, we’ve continued with our original staged release plan in order to provide the community with a test case of a full staged release process. We hope that this test case will be useful to developers of future powerful models, and we’re actively continuing the conversation with the AI community on responsible publication.},
	language = {en-US},
	urldate = {2025-06-09},
	month = jan,
	year = {2024},
}

@misc{dalle_2022,
	title = {{DALL}·{E}: creación de imágenes a partir de texto},
	shorttitle = {{DALL}·{E}},
	url = {https://openai.com/es-ES/index/dall-e/},
	abstract = {Hemos entrenado una red neuronal llamada DALL·E, que crea imágenes a partir de descripciones textuales para una amplia gama de conceptos expresables en lenguaje natural.},
	language = {es-ES},
	urldate = {2025-06-09},
	month = sep,
	year = {2022},
}

@misc{gpt-3_2024,
	title = {{GPT}-3 powers the next generation of apps},
	url = {https://openai.com/index/gpt-3-apps/},
	abstract = {Over 300 applications are delivering GPT-3–powered search, conversation, text completion, and other advanced AI features through our API.},
	language = {en-US},
	urldate = {2025-06-09},
	month = mar,
	year = {2024},
}

@misc{bloom,
	title = {{BLOOM}},
	url = {https://bigscience.huggingface.co/blog/bloom},
	abstract = {Our 176B parameter language model is here.},
	urldate = {2025-06-09},
}

@misc{stable_2025,
	title = {Stable {Diffusion}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://es.wikipedia.org/w/index.php?title=Stable_Diffusion&oldid=167403830},
	abstract = {Stable Diffusion es un modelo de aprendizaje automático desarrollado por Runway y LMU Múnich[1]​ para generar imágenes digitales de alta calidad a partir de descripciones en lenguaje natural o estímulos (prompts, en inglés). El modelo se puede usar para diferentes tareas, como la generación de traducciones de imagen a imagen guiadas por mensajes de texto y la mejora de imágenes.
A diferencia de modelos de la competencia como DALL-E, Stable Diffusion es de código abierto[2]​ y no limita artificialmente las imágenes que produce.[3]​ Los críticos han expresado su preocupación por la ética de la IA, afirmando que el modelo se puede utilizar para crear deepfakes.[4]​ Puede ejecutarse en el hardware del usuario equipado con una tarjeta gráfica (GPU), es completamente gratis, se puede acceder a él en línea y fue elogiado por PC World como «la próxima aplicación revolucionaria para su PC».[5]​ Desde su lanzamiento inicial, más de 200.000 personas han descargado el código.[6]​ El modelo original fue liberado a través de la colaboración de las comunidades CompVis LMU, Runway, y Stability AI, con el apoyo de EleutherAI y LAION.},
	language = {es},
	urldate = {2025-06-09},
	journal = {Wikipedia, la enciclopedia libre},
	month = may,
	year = {2025},
	note = {Page Version ID: 167403830},
}

@misc{TinyLlama,
	title = {{GitHub} - jzhang38/{TinyLlama}: {The} {TinyLlama} project is an open endeavor to pretrain a 1.{1B} {Llama} model on 3 trillion tokens.},
	shorttitle = {{GitHub} - jzhang38/{TinyLlama}},
	url = {https://github.com/jzhang38/TinyLlama},
	abstract = {The TinyLlama project is an open endeavor to pretrain a 1.1B Llama model on 3 trillion tokens. - jzhang38/TinyLlama},
	language = {en},
	urldate = {2025-06-09},
	journal = {GitHub},
}

@misc{llama_2023,
	title = {A brief history of {LLaMA} models - {AGI} {Sphere}},
	url = {https://agi-sphere.com/llama-models/},
	abstract = {LLaMA (Large Language Model Meta AI) is a language model released by Meta (Facebook). It is Meta's answer to OpenAI's GPT models. The LLaMA base model was},
	language = {en-US},
	urldate = {2025-06-09},
	month = apr,
	year = {2023},
}

@misc{phi-2_2023,
	title = {Phi-2: {The} surprising power of small language models},
	shorttitle = {Phi-2},
	url = {https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/},
	abstract = {Phi-2 is now accessible on the Azure model catalog. Its compact size and new innovations in model scaling and training data curation make it ideal for exploration around mechanistic interpretability, safety improvements, and fine-tuning experimentation on a variety of tasks.},
	language = {en-US},
	urldate = {2025-06-09},
	journal = {Microsoft Research},
	author = {Hughes, Alyssa},
	month = dec,
	year = {2023},
}

@Article{Lu2024SmallLM,
 author = {Zhenyan Lu and Xiang Li and Dongqi Cai and Rongjie Yi and Fangming Liu and Xiwen Zhang and N. Lane and Mengwei Xu},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {Small Language Models: Survey, Measurements, and Insights},
 volume = {abs/2409.15790},
 year = {2024}
}


@misc{destilación_2024,
	title = {¿{Qué} es la destilación del conocimiento? {\textbar} {IBM}},
	shorttitle = {¿{Qué} es la destilación del conocimiento?},
	url = {https://www.ibm.com/es-es/topics/knowledge-distillation},
	abstract = {La destilación de conocimientos es una técnica de machine learning utilizada para transferir el aprendizaje de un gran \&quot;modelo profesor\&quot; preentrenado a un \&quot;modelo alumno\&quot; más pequeño.},
	language = {es-es},
	urldate = {2025-06-12},
	month = apr,
	year = {2024},
}

@misc{o1_2024,
	title = {Aprender a razonar con los {LLM}},
	url = {https://openai.com/es-ES/index/learning-to-reason-with-llms/},
	abstract = {Presentamos OpenAI o1, un gran modelo de lenguaje entrenado con aprendizaje por refuerzo con el fin de llevar a cabo razonamientos complejos. El modelo o1 es capaz de generar una larga cadena interna de pensamientos antes de dar una respuesta.},
	language = {es-ES},
	urldate = {2025-06-12},
	month = sep,
	year = {2024},
}

@misc{claude,
	title = {Introducing the next generation of {Claude}},
	url = {https://www.anthropic.com/news/claude-3-family},
	abstract = {Today, we're announcing the Claude 3 model family, which sets new industry benchmarks across a wide range of cognitive tasks. The family includes three state-of-the-art models in ascending order of capability: Claude 3 Haiku, Claude 3 Sonnet, and Claude 3 Opus.},
	language = {en},
	urldate = {2025-06-09},
}

@misc{tokenization,
	title = {Tokenization {\textbar} {Mistral} {AI} {Large} {Language} {Models}},
	url = {https://docs.mistral.ai/guides/tokenization/},
	abstract = {Tokenization is a fundamental step in LLMs. It is the process of breaking down text into smaller subword units, known as tokens. We recently open-sourced our tokenizer at Mistral AI. This guide will walk you through the fundamentals of tokenization, details about our open-source tokenizers, and how to use our tokenizers in Python.},
	language = {en},
	urldate = {2025-06-12},
}

@misc{attention_2023,
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	doi = {10.48550/arXiv.1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	urldate = {2025-06-09},
	publisher = {arXiv},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = aug,
	year = {2023},
	note = {arXiv:1706.03762},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{tiktoken_encoding,
	title = {How to count tokens with {Tiktoken} {\textbar} {OpenAI} {Cookbook}},
	url = {https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken},
	abstract = {Open-source examples and guides for building with the OpenAI API. Browse a collection of snippets, advanced techniques and walkthroughs. Share your own examples and guides.},
	language = {en},
	author = {Sanders, Ted},
	urldate = {2025-06-13},
	month = dec,
	year = {2022},
}

@misc{espejel_getting_2022,
	title = {Getting {Started} {With} {Embeddings}},
	url = {https://huggingface.co/blog/getting-started-with-embeddings},
	urldate = {2025-06-13},
	author = {Espejel, Omar },
	month = jun,
	year = {2022},
}

@misc{nachane_few_2024,
	title = {Few shot chain-of-thought driven reasoning to prompt {LLMs} for open ended medical question answering},
	url = {http://arxiv.org/abs/2403.04890},
	doi = {10.48550/arXiv.2403.04890},
	urldate = {2025-06-13},
	publisher = {arXiv},
	author = {Nachane, Saeel Sandeep and Gramopadhye, Ojas and Chanda, Prateek and Ramakrishnan, Ganesh and Jadhav, Kshitij Sharad and Nandwani, Yatin and Raghu, Dinesh and Joshi, Sachindra},
	month = oct,
	year = {2024},
	note = {arXiv:2403.04890},
	keywords = {Computer Science - Computation and Language},
}

@misc{fine-tuning_hf,
	title = {Fine-tuning},
	url = {https://huggingface.co/docs/transformers/en/training},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2025-06-13},
}

@misc{ibm_attention_2024,
	title = {¿{Qué} es un mecanismo de atención? {\textbar} {IBM}},
	shorttitle = {¿{Qué} es un mecanismo de atención?},
	url = {https://www.ibm.com/es-es/think/topics/attention-mechanism},
	abstract = {Un mecanismo de atención es una técnica de machine learning que orienta a los modelos de deep learning, como los transformadores, para que se centren en las partes más relevantes de los datos de entrada.},
	language = {es-es},
	urldate = {2025-06-13},
	month = dec,
	year = {2024},
}

@misc{fig_2_1,
	title = {Word embedding illustration},
	url = {https://commons.wikimedia.org/wiki/File:Word_embedding_illustration.svg},
	urldate = {2025-06-13},
	author = {{Fschwarzentruber}},
	month = mar,
	year = {2025},
}

@misc{fig_2_2,
	title = {Constructing {Transformers} {For} {Longer} {Sequences} with {Sparse} {Attention} {Methods}},
	url = {https://research.google/blog/constructing-transformers-for-longer-sequences-with-sparse-attention-methods/},
	language = {en},
	urldate = {2025-06-13},
	author = {Avinava, Dubey},
}

@book{jurafsky_speech_2009,
	address = {Upper Saddle River, NJ},
	edition = {2. ed. [Nachdr.]},
	title = {Speech and language processing: an introduction to natural language processing, computational linguistics, and speech recognition},
	isbn = {9780131873216},
	shorttitle = {Speech and language processing},
	language = {eng},
	publisher = {Prentice Hall},
	author = {Jurafsky, Dan and Martin, James H.},
	year = {2009},
}

@misc{textsynth_completion,
	title = {Text {Completion}},
	url = {https://textsynth.com/completion.html},
	urldate = {2025-06-13},
}

@misc{martineau_what_2021,
	title = {What is {AI} inferencing?},
	copyright = {© Copyright IBM Corp. 2021},
	url = {https://research.ibm.com/blog/AI-inference-explained},
	abstract = {Inferencing is how you run live data through a trained AI model to make a prediction or solve a task.},
	language = {en-US},
	urldate = {2025-06-13},
	journal = {IBM Research},
	author = {Martineau, Kim},
	month = feb,
	year = {2021},
}

@misc{templates_hf,
	title = {Templates},
	url = {https://huggingface.co/docs/transformers/main/chat_templating},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2025-06-13},
}

@misc{quantization_hf,
	title = {Quantization},
	url = {https://huggingface.co/docs/optimum/concept_guides/quantization},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2025-06-13},
}

@misc{bergmann_imb_2023,
	title = {¿{Qué} es la destilación del conocimiento?},
	shorttitle = {¿{Qué} es la destilación del conocimiento?},
	url = {https://www.ibm.com/es-es/topics/knowledge-distillation},
	abstract = {La destilación de conocimientos es una técnica de machine learning utilizada para transferir el aprendizaje de un gran \&quot;modelo profesor\&quot; preentrenado a un \&quot;modelo alumno\&quot; más pequeño.},
	language = {es-es},
	urldate = {2025-06-13},
	journal = {IBM},
	author = {Bergmann, Dave},
	month = dec,
	year = {2023},
}

@misc{gguf_2024,
	title = {{GGUF} versus {GGML} {\textbar} {IBM}},
	url = {https://www.ibm.com/think/topics/gguf-versus-ggml},
	abstract = {GGUF (GPT-Generated Unified Format) is a file format designed to simplify the use and deployment of large language models (LLMs) and is designed to perform well on consumer-grade computer hardware.},
	language = {en},
	urldate = {2025-06-09},
	author = {Mucci, Tim},
	month = jul,
	year = {2024},
}

@misc{hugging_2025,
	title = {Hugging {Face} – {The} {AI} community building the future.},
	url = {https://huggingface.co/},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2025-06-09},
	month = may,
	year = {2025},
}

@misc{onnx_2025,
	title = {onnx/onnx},
	copyright = {Apache-2.0},
	url = {https://github.com/onnx/onnx},
	abstract = {Open standard for machine learning interoperability},
	urldate = {2025-06-09},
	publisher = {Open Neural Network Exchange},
	month = jun,
	year = {2025},
	note = {original-date: 2017-09-07T04:53:45Z},
	keywords = {machine-learning, deep-neural-networks, deep-learning, neural-network, tensorflow, scikit-learn, keras, ml, dnn, pytorch, onnx},
}

@misc{eliza_2025,
	title = {{ELIZA}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=ELIZA&oldid=1293051533},
	abstract = {ELIZA is an early natural language processing computer program developed from 1964 to 1967 at MIT by Joseph Weizenbaum. Created to explore communication between humans and machines, ELIZA simulated conversation by using a pattern matching and substitution methodology that gave users an illusion of understanding on the part of the program, but had no representation that could be considered really understanding what was being said by either party. Whereas the ELIZA program itself was written (originally) in MAD-SLIP, the pattern matching directives that contained most of its language capability were provided in separate "scripts", represented in a lisp-like representation. The most famous script, DOCTOR, simulated a psychotherapist of the Rogerian school (in which the therapist often reflects back the patient's words to the patient), and used rules, dictated in the script, to respond with non-directional questions to user inputs. As such, ELIZA was one of the first chatterbots ("chatbot" modernly) and one of the first programs capable of attempting the Turing test.
Weizenbaum intended the program as a method to explore communication between humans and machines. He was surprised and shocked that some people, including his secretary, attributed human-like feelings to the computer program, a phenomenon that came to be called the Eliza effect. Many academics believed that the program would be able to positively influence the lives of many people, particularly those with psychological issues, and that it could aid doctors working on such patients' treatment. While ELIZA was capable of engaging in discourse, it could not converse with true understanding. However, many early users were convinced of ELIZA's intelligence and understanding, despite Weizenbaum's insistence to the contrary. 
The original ELIZA source code had been missing since its creation in the 1960s, as it was not common to publish articles that included source code at that time. However, more recently the MAD-SLIP source code was discovered in the MIT archives and published on various platforms, such as the Internet Archive. The source code is of high historical interest since it demonstrates not only the specificity of programming languages and techniques at that time, but also the beginning of software layering and abstraction as a means of achieving sophisticated software programming.},
	language = {en},
	urldate = {2025-06-09},
	journal = {Wikipedia},
	month = may,
	year = {2025},
	note = {Page Version ID: 1293051533},
}

@misc{openai,
	title = {{OpenAI} {Platform}},
	url = {https://platform.openai.com},
	abstract = {Explore developer resources, tutorials, API docs, and dynamic examples to get the most out of OpenAI's platform.},
	language = {en},
	urldate = {2025-06-09},
}

@misc{gemini,
	title = {Introducing {Gemini}: our largest and most capable {AI} model},
	shorttitle = {Introducing {Gemini}},
	url = {https://blog.google/technology/ai/google-gemini-ai/},
	abstract = {Gemini is our most capable and general model, built to be multimodal and optimized for three different sizes: Ultra, Pro and Nano.},
	language = {en-us},
	urldate = {2025-06-09},
	journal = {Google},
	month = dec,
	year = {2023},
}

@misc{claude,
	title = {Meet {Claude} {\textbackslash} {Anthropic}},
	url = {https://www.anthropic.com/claude},
	abstract = {Claude is AI for all of us. Whether you're brainstorming alone or building with a team of thousands, Claude is here to help.},
	language = {en},
	urldate = {2025-06-09},
}

@misc{deepseek-r1_2025,
	title = {deepseek-ai/{DeepSeek}-{R1} · {Hugging} {Face}},
	url = {https://huggingface.co/deepseek-ai/DeepSeek-R1},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2025-06-09},
	month = may,
	year = {2025},
}

@misc{github_2025,
	title = {{GitHub} {Copilot} · {Your} {AI} pair programmer},
	url = {https://github.com/features/copilot},
	abstract = {GitHub Copilot works alongside you directly in your editor, suggesting whole lines or entire functions for you.},
	language = {en},
	urldate = {2025-06-09},
	journal = {GitHub},
	year = {2025},
}

@misc{grok_2025,
	title = {Grok (chatbot)},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://es.wikipedia.org/w/index.php?title=Grok_(chatbot)&oldid=167769604},
	abstract = {Grok es un chatbot de inteligencia artificial generativa desarrollado por xAI, basado en grandes modelos de lenguaje. Fue desarrollado como una iniciativa de Elon Musk como respuesta al surgimiento de ChatGPT.[1]​ El chatbot fue promocionado como «con sentido del humor» y con acceso directo a X (anteriormente conocido como Twitter).[2]​ [3]​},
	language = {es},
	urldate = {2025-06-09},
	journal = {Wikipedia, la enciclopedia libre},
	month = jun,
	year = {2025},
	note = {Page Version ID: 167769604},
}

@misc{mistral,
	title = {Frontier {AI} {LLMs}, assistants, agents, services {\textbar} {Mistral} {AI}},
	url = {https://mistral.ai/},
	abstract = {The most powerful AI platform for enterprises. Customize, fine-tune, and deploy AI assistants, autonomous agents, and multimodal AI with open models.},
	language = {en},
	urldate = {2025-06-09},
}

@misc{o3_o4,
	title = {Presentamos {OpenAI} o3 y o4-mini},
	url = {https://openai.com/es-ES/index/introducing-o3-and-o4-mini/},
	abstract = {Nuestros modelos más inteligentes y con más capacidades hasta ahora, y con acceso a todas las herramientas},
	language = {es-ES},
	urldate = {2025-06-09},
}

@misc{NPUs,
	title = {All about neural processing units ({NPUs}) - {Microsoft} {Support}},
	url = {https://support.microsoft.com/en-us/windows/all-about-neural-processing-units-npus-e77a5637-7705-4915-96c8-0c6a975f9db4},
	abstract = {Learn about neural processing units and the advantages they provide.},
	urldate = {2025-06-09},
}

@misc{notion,
	title = {Notion {AI}},
	url = {https://www.notion.com/help/guides/category/ai},
	abstract = {Learn how to use Notion for a variety of use cases. Whether youʼre looking to create a project management system or a 1:1 doc, Notion can help.},
	language = {en-us},
	urldate = {2025-06-09},
	journal = {Notion},
}

@misc{le_chat,
	title = {Le {Chat} {\textbar} {Mistral} {AI}},
	url = {https://mistral.ai/news/le-chat-mistral},
	abstract = {Our assistant is now in beta access, demonstrating what can be built with our technology.},
	language = {en},
	urldate = {2025-06-09},
}

@misc{WebUI,
	title = {🏡 {Home} {\textbar} {Open} {WebUI}},
	url = {https://openwebui.com/},
	abstract = {Open WebUI is an extensible, feature-rich, and user-friendly self-hosted AI platform designed to operate entirely offline. It supports various LLM runners like Ollama and OpenAI-compatible APIs, with built-in inference engine for RAG, making it a powerful AI deployment solution.},
	language = {en},
	urldate = {2025-06-09},
}

@misc{enchanted_2025,
	title = {gluonfield/enchanted},
	copyright = {Apache-2.0},
	url = {https://github.com/gluonfield/enchanted},
	abstract = {Enchanted is iOS and macOS app for chatting with private self hosted language models such as Llama2, Mistral or Vicuna using Ollama.},
	urldate = {2025-06-09},
	author = {Malinauskas, Augustinas},
	month = jun,
	year = {2025},
	note = {original-date: 2023-12-13T18:55:26Z},
	keywords = {swift, ios, llama, mistral, llm, large-language-model, llama2, ollama, ollama-app},
}

@misc{hollama_2025,
	title = {fmaclen/hollama},
	copyright = {MIT},
	url = {https://github.com/fmaclen/hollama},
	abstract = {A minimal LLM chat app that runs entirely in your browser},
	urldate = {2025-06-09},
	author = {Maclen, Fernando},
	month = jun,
	year = {2025},
	note = {original-date: 2023-11-25T20:21:57Z},
	keywords = {ai, chatbot, llm, local-ai, ollama},
}

@misc{librechat,
	title = {{LibreChat}},
	url = {https://librechat.ai/},
	abstract = {Free, open source AI chat platform - Every AI for Everyone},
	urldate = {2025-06-09},
}

@misc{lm_studio,
	title = {{LM} {Studio} - {Discover}, download, and run local {LLMs}},
	url = {https://lmstudio.ai},
	abstract = {Run Llama, Gemma 3, DeepSeek locally on your computer.},
	language = {en},
	urldate = {2025-06-09},
	journal = {LM Studio},
}

@misc{msty,
	title = {Msty},
	url = {https://msty.ai/},
	abstract = {Unleash the power of your AI with Msty Studio.},
	urldate = {2025-06-09},
}

@misc{gpt4all_2025,
	title = {nomic-ai/gpt4all},
	copyright = {MIT},
	url = {https://github.com/nomic-ai/gpt4all},
	abstract = {GPT4All: Run Local LLMs on Any Device. Open-source and available for commercial use.},
	urldate = {2025-06-09},
	publisher = {Nomic AI},
	month = jun,
	year = {2025},
	note = {original-date: 2023-03-27T18:49:32Z},
	keywords = {ai-chat, llm-inference},
}

@misc{jan_ai,
	title = {Jan: {Open} source {ChatGPT}-alternative that runs 100\% offline - {Jan}},
	shorttitle = {Jan},
	url = {https://jan.ai},
	abstract = {Chat with AI without privacy concerns. Jan is an open-source alternative to ChatGPT, running AI models locally on your device.},
	language = {en},
	urldate = {2025-06-09},
}

@misc{anythingllm,
	title = {{AnythingLLM} {\textbar} {The} all-in-one {AI} application for everyone},
	url = {https://anythingllm.com/},
	abstract = {AnythingLLM is the AI application you've been seeking. Use any LLM to chat with your documents, enhance your productivity, and run the latest state-of-the-art LLMs completely privately with no technical setup.},
	language = {en-US},
	urldate = {2025-06-09},
}

@misc{winui,
	title = {{WinUI} 3 - {Windows} apps},
	url = {https://learn.microsoft.com/en-us/windows/apps/winui/winui3/},
	abstract = {Provides info for WinUI 3 and Windows app development with the Windows App SDK.},
	language = {en-us},
	urldate = {2025-06-09},
	author = {{Karl-Bridge-Microsoft}},
}

@misc{azure,
	title = {Azure {AI} {Foundry} documentation},
	url = {https://learn.microsoft.com/en-us/azure/ai-foundry/},
	abstract = {The agent factory - Design, customize, manage, and support AI applications and agents at scale.},
	language = {en-us},
	urldate = {2025-06-09},
	author = {{eric-urban}},
}

@misc{Mvvm_messaging,
	title = {Introduction to the {MVVM} {Toolkit} - {Community} {Toolkits} for .{NET}},
	url = {https://learn.microsoft.com/en-us/dotnet/communitytoolkit/mvvm/},
	abstract = {An overview of how to get started with the MVVM Toolkit and to the APIs it contains},
	language = {en-us},
	urldate = {2025-06-09},
	author = {{Sergio0694}},
}

@misc{xaml,
	title = {{XAML} language overview - {WPF}},
	url = {https://learn.microsoft.com/en-us/dotnet/desktop/wpf/xaml/},
	abstract = {Learn how the XAML language is structured and implemented by Windows Presentation Foundation (WPF) for .NET.},
	language = {en-us},
	urldate = {2025-06-09},
	author = {{adegeo}},
}

@misc{webview2,
	title = {Introducción a {Microsoft} {Edge} {WebView2} - {Microsoft} {Edge} {Developer} documentation},
	url = {https://learn.microsoft.com/es-es/microsoft-edge/webview2/},
	abstract = {Hospedar contenido web en las aplicaciones de Win32, .NET y UWP con el control WebView2 de Microsoft Edge.},
	language = {es-es},
	urldate = {2025-06-09},
	author = {{MSEdgeTeam}},
}

@misc{pinvoke,
	title = {Invocación de plataforma ({P}/{Invoke}) - .{NET}},
	url = {https://learn.microsoft.com/es-es/dotnet/standard/native-interop/pinvoke},
	abstract = {Obtenga información sobre cómo llamar a funciones nativas a través de P/Invoke en. NET.},
	language = {es-es},
	urldate = {2025-06-09},
	author = {{jkoritzinsky}},
}

@misc{system.text.json,
	title = {System.{Text}.{Json} {Espacio} de nombres},
	url = {https://learn.microsoft.com/es-es/dotnet/api/system.text.json?view=net-8.0},
	abstract = {Proporciona funciones de alto rendimiento, asignación baja y conformes a los estándares para procesar notación de objetos JavaScript (JSON). Incluye serialización de objetos a texto JSON y deserialización de texto JSON a objetos, con compatibilidad con UTF-8 integrada. También proporciona tipos para leer y escribir texto JSON codificado como UTF-8, y para crear un modelo de objetos de documento (DOM) en memoria para el acceso aleatorio de los elementos JSON dentro de una vista estructurada de los datos.},
	language = {es-es},
	urldate = {2025-06-09},
	author = {{dotnet-bot}},
}

@misc{cswin32_2025,
	title = {microsoft/{CsWin32}},
	copyright = {MIT},
	url = {https://github.com/microsoft/CsWin32},
	abstract = {A source generator to add a user-defined set of Win32 P/Invoke methods and supporting types to a C\# project.},
	urldate = {2025-06-10},
	publisher = {Microsoft},
	month = jun,
	year = {2025},
	note = {original-date: 2020-12-01T18:59:20Z},
}

@misc{docfx,
	title = {Quick {Start} {\textbar} docfx},
	url = {https://dotnet.github.io/docfx/},
	urldate = {2025-06-10},
}

@misc{sandcastle,
	title = {Welcome},
	url = {https://ewsoftware.github.io/SHFB/html/bd1ddb51-1c4f-434f-bb1a-ce2135d3a909.htm},
	urldate = {2025-06-10},
}

@misc{doxygen,
	title = {doxygen/doxygen},
	copyright = {GPL-2.0},
	url = {https://github.com/doxygen/doxygen},
	abstract = {Official doxygen git repository},
	urldate = {2025-06-10},
	author = {Heesch, Dimitri van},
	month = jun,
	year = {2025},
	note = {original-date: 2013-05-19T19:16:07Z},
	keywords = {doxygen, doxygen-documentation},
}

@misc{SonarQube,
	title = {Linter {IDE} {Tool} \& {Real}-{Time} {Software} for {Code} {\textbar} {Sonar}},
	url = {https://www.sonarsource.com/products/sonarlint/},
	abstract = {A code quality and code security linter for your VS Code, IntelliJ, Windsurf, Trae, Cursor, GitHub Codespaces IDEs to help find \& fix bugs, security issues \& analysis across popular programming languages to provide real-time feedback. Integrate easily into your workflows to ensure code quality and code security.},
	language = {en},
	urldate = {2025-06-10},
}

@misc{.net,
	title = {.{NET} {Coding} {Conventions} - {C}\#},
	url = {https://learn.microsoft.com/en-us/dotnet/csharp/fundamentals/coding-style/coding-conventions},
	abstract = {Learn about commonly used coding conventions in C\#. Coding conventions create a consistent look to the code and facilitate copying, changing, and maintaining the code. This article also includes the docs repo coding guidelines},
	language = {en-us},
	urldate = {2025-06-10},
	author = {{BillWagner}},
}

@misc{iDisposable,
	title = {Implementación de un método {Dispose} - .{NET}},
	url = {https://learn.microsoft.com/es-es/dotnet/standard/garbage-collection/implementing-dispose},
	abstract = {En este artículo, aprenderá a implementar el método Dispose, que libera recursos no administrados usados por el código en .NET.},
	language = {es-es},
	urldate = {2025-06-10},
	author = {{gewarren}},
}

@misc{using,
	title = {using statement - ensure the correct use of disposable objects - {C}\# reference},
	url = {https://learn.microsoft.com/en-us/dotnet/csharp/language-reference/statements/using},
	abstract = {Use the C\# using statement or declaration to ensure the correct use of disposable objects},
	language = {en-us},
	urldate = {2025-06-10},
	author = {{BillWagner}},
}

@misc{json_serializable,
	title = {How to use source generation in {System}.{Text}.{Json} - .{NET}},
	url = {https://learn.microsoft.com/en-us/dotnet/standard/serialization/system-text-json/source-generation},
	abstract = {Learn how to use source generation in System.Text.Json.},
	language = {en-us},
	urldate = {2025-06-10},
	author = {{gewarren}},
}

@misc{nuget,
	title = {{NuGet} {Gallery} {\textbar} {Home}},
	url = {https://www.nuget.org/},
	abstract = {The NuGet Gallery is the central package repository for NuGet, the package manager for .NET.},
	language = {en},
	urldate = {2025-06-10},
}


@misc{microsoft.extensions,
	title = {Microsoft.{Extensions}.{AI} libraries - .{NET}},
	url = {https://learn.microsoft.com/en-us/dotnet/ai/microsoft-extensions-ai},
	abstract = {Learn how to use the Microsoft.Extensions.AI libraries to integrate and interact with various AI services in your .NET applications.},
	language = {en-us},
	urldate = {2025-06-10},
	author = {{IEvangelist}},
}

@misc{extensions.ai.abstractions,
	title = {extensions/src/{Libraries}/{Microsoft}.{Extensions}.{AI}.{Abstractions}/{README}.md at main · dotnet/extensions},
	url = {https://github.com/dotnet/extensions/blob/main/src/Libraries/Microsoft.Extensions.AI.Abstractions/README.md},
	abstract = {This repository contains a suite of libraries that provide facilities commonly needed when creating production-ready applications. - dotnet/extensions},
	language = {en},
	urldate = {2025-06-10},
	journal = {GitHub},
}

@misc{azure.extensions,
	title = {{AzureAIInferenceExtensions} {Class} ({Microsoft}.{Extensions}.{AI})},
	url = {https://learn.microsoft.com/en-us/dotnet/api/microsoft.extensions.ai.azureaiinferenceextensions?view=net-9.0-pp},
	abstract = {Provides extension methods for working with Azure AI Inference.},
	language = {en-us},
	urldate = {2025-06-10},
	author = {{dotnet-bot}},
}

@misc{microsoft.extensions.openai,
	title = {Microsoft.{Extensions}.{AI}.{OpenAI} 9.5.0-preview.1.25265.7},
	url = {https://nuget.org/packages/Microsoft.Extensions.AI.OpenAI/},
	abstract = {Implementation of generative AI abstractions for OpenAI-compatible endpoints.},
	language = {en},
	urldate = {2025-06-10},
}

@misc{ollamasharp_2025,
	title = {awaescher/{OllamaSharp}},
	copyright = {MIT},
	url = {https://github.com/awaescher/OllamaSharp},
	abstract = {The easiest way to use the Ollama API in .NET},
	urldate = {2025-06-10},
	author = {Wäscher, Andreas},
	month = jun,
	year = {2025},
	note = {original-date: 2023-10-15T19:36:33Z},
	keywords = {library, streaming, ai, llama, gpt, llm, llamacpp, ollama, ollama-api, localllama, microsoft-extensions-ai, ichatclient},
}

@misc{agility,
	title = {Html {Agility} {Pack}},
	url = {https://html-agility-pack.net/},
	abstract = {Learn Html Agility pack using Html Agility Pack (HAP) by documentation \& example},
	urldate = {2025-06-10},
}

@misc{community_toolkit,
	title = {Community {Toolkit}},
	url = {https://github.com/CommunityToolkit},
	abstract = {The Community Toolkit organization holds a collection of control \& helper libraries and samples for various .NET technologies. Part of the .NET Foundation. - Community Toolkit},
	language = {en},
	urldate = {2025-06-10},
	journal = {GitHub},
}

@misc{toolkit_mvvm,
	title = {Introducción al kit de herramientas {MVVM} - {Community} {Toolkits} for .{NET}},
	url = {https://learn.microsoft.com/es-es/dotnet/communitytoolkit/mvvm/},
	abstract = {Información general sobre cómo empezar a trabajar con el kit de herramientas de MVVM y las API que contiene},
	language = {es-es},
	urldate = {2025-06-10},
	author = {{Sergio0694}},
}

@misc{toolkit.winui,
	title = {{CommunityToolkit}.{WinUI}.{UI}.{Controls}.{Primitives} {Namespace}},
	url = {https://learn.microsoft.com/en-us/dotnet/api/communitytoolkit.winui.ui.controls.primitives?view=win-comm-toolkit-dotnet-7.0},
	abstract = {Explore all classes and interfaces of the CommunityToolkit.WinUI.UI.Controls.Primitives namespace.},
	language = {en-us},
	urldate = {2025-06-10},
	author = {{dotnet-bot}},
}

@misc{toolkit.converters,
	title = {Converters - {Community} {Toolkits} for .{NET}},
	url = {https://learn.microsoft.com/en-us/dotnet/communitytoolkit/windows/converters/},
	abstract = {Commonly used converters that allow the data to be modified as it passes through the binding engine.},
	language = {en-us},
	urldate = {2025-06-10},
	author = {{niels9001}},
}

@misc{controls.primitives,
	title = {{CommunityToolkit}.{WinUI}.{Controls}.{Primitives} 8.2.250402},
	url = {https://nuget.org/packages/CommunityToolkit.WinUI.Controls.Primitives/},
	abstract = {Primitive layout controls such as SwitchPresenter, UniformGrid, WrapLayout, StaggeredPanel, WrapPanel, DockPanel, ConstrainedBox and more.},
	language = {en},
	urldate = {2025-06-10},
}


@misc{notifyicon,
	title = {{GitHub} - {HavenDV}/{H}.{NotifyIcon}: {TrayIcon} for {WPF}/{WinUI}/{Uno}/{MAUI}},
	shorttitle = {{GitHub} - {HavenDV}/{H}.{NotifyIcon}},
	url = {https://github.com/HavenDV/H.NotifyIcon},
	abstract = {TrayIcon for WPF/WinUI/Uno/MAUI. Contribute to HavenDV/H.NotifyIcon development by creating an account on GitHub.},
	language = {en},
	urldate = {2025-06-10},
	journal = {GitHub},
}

@misc{extensions.dependencyinjection,
	title = {Microsoft.{Extensions}.{DependencyInjection} {Namespace}},
	url = {https://learn.microsoft.com/en-us/dotnet/api/microsoft.extensions.dependencyinjection?view=net-9.0-pp},
	abstract = {Provides classes that support the implementation of the dependency injection software design pattern.},
	language = {en-us},
	urldate = {2025-06-10},
	author = {{dotnet-bot}},
}

@misc{windowsAppSDK,
	title = {{GitHub} - microsoft/{WindowsAppSDK}: {The} {Windows} {App} {SDK} empowers all {Windows} desktop apps with modern {Windows} {UI}, {APIs}, and platform features, including back-compat support, shipped via {NuGet}.},
	shorttitle = {{GitHub} - microsoft/{WindowsAppSDK}},
	url = {https://github.com/microsoft/WindowsAppSDK},
	abstract = {The Windows App SDK empowers all Windows desktop apps with modern Windows UI, APIs, and platform features, including back-compat support, shipped via NuGet. - microsoft/WindowsAppSDK},
	language = {en},
	urldate = {2025-06-10},
	journal = {GitHub},
}

@misc{winUIEx,
	title = {{GitHub} - {dotMorten}/{WinUIEx}: {WinUI} {Extensions}},
	shorttitle = {{GitHub} - {dotMorten}/{WinUIEx}},
	url = {https://github.com/dotMorten/WinUIEx},
	abstract = {WinUI Extensions. Contribute to dotMorten/WinUIEx development by creating an account on GitHub.},
	language = {en},
	urldate = {2025-06-10},
	journal = {GitHub},
}

@misc{cswin32_2025,
	title = {microsoft/{CsWin32}},
	copyright = {MIT},
	url = {https://github.com/microsoft/CsWin32},
	abstract = {A source generator to add a user-defined set of Win32 P/Invoke methods and supporting types to a C\# project.},
	urldate = {2025-06-10},
	publisher = {Microsoft},
	month = jun,
	year = {2025},
	note = {original-date: 2020-12-01T18:59:20Z},
}

@misc{buildtools,
	title = {Microsoft.{Windows}.{SDK}.{BuildTools} is missing {buildTransitive} · {Issue} \#3251 · microsoft/{WindowsAppSDK}},
	url = {https://github.com/microsoft/WindowsAppSDK/issues/3251},
	abstract = {Describe the bug When including Microsoft.Windows.SDK.BuildTools transitively - for example you have a reference to the WASDK - it does not bring in the Microsoft.Windows.SDK.BuildTools targets. Th...},
	language = {en},
	urldate = {2025-06-10},
	journal = {GitHub},
}

@misc{manifest,
	title = {Manifiesto del paquete de la aplicación - {Windows} {UWP} applications},
	url = {https://learn.microsoft.com/es-es/uwp/schemas/appxpackage/appx-package-manifest},
	abstract = {El manifiesto del paquete es un documento XML que contiene la información que el sistema necesita para implementar, mostrar o actualizar una Windows aplicación.},
	language = {es-es},
	urldate = {2025-06-10},
	author = {{drewbatgit}},
}

@misc{gdpr,
	title = {General {Data} {Protection} {Regulation} ({GDPR}) {Compliance} {Guidelines}},
	url = {https://gdpr.eu/},
	abstract = {The EU General Data Protection Regulation went into effect on May 25, 2018, replacing the Data Protection Directive 95/46/EC. Designed to increase data privacy for EU citizens, the regulation levies steep fines on organizations that don’t follow the law.},
	language = {en-US},
	urldate = {2025-06-10},
	journal = {GDPR.eu},
}

@Inproceedings{ciberseguridad_privacidad,
 author = {Roberto Gil-Miñano},
 title = {La ciberseguridad como solución de privacidad: Especial incidencia en la privacidad desde el diseño},
 year = {2020}
}

@misc{RGPD,
	title = {Ethics guidelines for trustworthy {AI} {\textbar} {Shaping} {Europe}’s digital future},
	url = {https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai},
	abstract = {On 8 April 2019, the High-Level Expert Group on AI presented Ethics Guidelines for Trustworthy Artificial Intelligence. This followed the publication of the guidelines' first draft in December 2018 on which more than 500 comments were received through an open consultation.},
	language = {en},
	urldate = {2025-06-10},
}

@misc{solid_2024,
	title = {{SOLID}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://es.wikipedia.org/w/index.php?title=SOLID&oldid=156873545},
	abstract = {En ingeniería de software, SOLID (Single responsibility, Open-closed, Liskov substitution, Interface segregation and Dependency inversion) es un acrónimo mnemónico introducido por Robert C. Martin[1]​ a comienzos de la década del 2000[2]​ que representa cinco principios básicos de la programación orientada a objetos y el diseño. Cuando estos principios se aplican en conjunto es más probable que un desarrollador cree un sistema que sea fácil de mantener y ampliar con el tiempo.[3]​ Los principios SOLID son guías que pueden ser aplicadas en el desarrollo de software para eliminar malos diseños provocando que el programador tenga que refactorizar el código fuente hasta que sea legible y extensible. Puede ser utilizado con el desarrollo guiado por pruebas, y forma parte de la estrategia global del desarrollo ágil de software y desarrollo adaptativo de software.},
	language = {es},
	urldate = {2025-06-10},
	journal = {Wikipedia, la enciclopedia libre},
	month = jan,
	year = {2024},
	note = {Page Version ID: 156873545},
}

@misc{winui_3,
	title = {{WinUI} 3 and {Uno} {Platform}},
	url = {https://platform.uno/docs/articles/uwp-vs-winui3.html},
	urldate = {2025-06-10},
}