# Resumen

El presente trabajo se centra en el desarrollo de una aplicación de escritorio que permite la interacción con modelos de lenguaje de gran tamaño (**LLMs**) de forma local, combinando accesibilidad, personalización y eficiencia. La solución propuesta utiliza **Ollama** como motor de ejecución y eliminando la dependencia de servicios en la nube, garantizando así **privacidad, control sobre los datos y optimización del rendimiento** en hardware local.

El sistema se concibe como una herramienta **productiva e intuitiva**, que integra en un mismo entorno la **gestión de notas, la administración de conversaciones con IA y la personalización de agentes**. A través de una interfaz moderna basada en **WinUI3 con .NET**, los usuarios podrán acceder a capacidades avanzadas de IA local, como **conversaciones, edición de texto y generación de contenido**, con la posibilidad de configurar agentes personalizados para **resumir, traducir, corregir y mejorar textos** sin necesidad de abandonar su flujo de trabajo. Además, se implementa un **diálogo de edición rápida**, que facilita la interacción con los agentes y optimiza la experiencia del usuario.

Uno de los aspectos diferenciadores del proyecto es la capacidad de **gestionar modelos de IA en local de forma sencilla**, permitiendo la **búsqueda, descarga, actualización y configuración** de modelos sin necesidad de conocimientos técnicos avanzados. Asimismo, se incluye la posibilidad de operar en un **entorno híbrido**, almacenando las conversaciones y notas de forma totalmente local, pero permitiendo la conexión con modelos alojados en servidores privados o en la nube según las preferencias del usuario.

En el ámbito teórico, el proyecto incluye una breve documentación sobre el estado del arte de la inteligencia artificial generativa, un repaso sobre su historia y un **análisis de la competencia**, identificando los factores diferenciadores frente a herramientas similares a la propuesta.

Más allá del impacto técnico, se analizan los aspectos **sociales, éticos y ambientales** de la inteligencia artificial generativa, así como el papel de este proyecto en la democratización del acceso a modelos de IA de código abierto.

En conclusión, este trabajo presenta una solución innovadora que **integra modelos de IA en el flujo de trabajo del usuario de manera fluida y eficiente, sin comprometer la privacidad ni la seguridad de los datos**. Con su enfoque **modular y escalable**, la aplicación sienta las bases para futuras extensiones y mejoras, presentándose como una herramienta clave para la **productividad asistida por IA en entornos locales**.

# Abstract

The present work focuses on the development of a desktop application that allows interaction with large language models (**LLMs**) locally, combining accessibility, customization, and efficiency. The proposed solution uses **Ollama** as the execution engine, eliminating the dependency on cloud services, thus ensuring **privacy, control over data, and performance optimization** on local hardware.

The system is conceived as a **productive and intuitive** tool, integrating in a single environment the **management of notes, administration of AI conversations, and customization of agents**. Through a modern interface based on **WinUI3 with .NET**, users will be able to access advanced local AI capabilities, such as **conversations, text editing, and content generation**, with the possibility of configuring personalized agents to **summarize, translate, correct, and enhance texts** without leaving their workflow. Additionally, a **quick edit dialog** is implemented, facilitating interaction with agents and optimizing the user experience.

One of the distinguishing aspects of the project is the ability to **manage AI models locally in a simple way**, allowing for the **search, download, update, and configuration** of models without the need for advanced technical knowledge. Furthermore, it includes the possibility to operate in a **hybrid environment**, storing conversations and notes entirely locally, but allowing connection with models hosted on private servers or in the cloud according to user preferences.

In the theoretical realm, the project includes a brief documentation on the state of the art of generative artificial intelligence, a review of its history, and a **competition analysis**, identifying differentiating factors compared to tools similar to the proposal.

Beyond the technical impact, the **social, ethical, and environmental** aspects of generative artificial intelligence are analyzed, as well as the role of this project in democratizing access to open-source AI models.

In conclusion, this work presents an innovative solution that **integrates AI models into the user's workflow smoothly and efficiently, without compromising privacy or data security**. With its **modular and scalable** approach, the application lays the foundation for future extensions and improvements, presenting itself as a key tool for **AI-assisted productivity in local environments**.